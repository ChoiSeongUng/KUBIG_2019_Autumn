{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Deep Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Due date : Sat. 10/12 11:59pm     \n",
    "* 이 과제는 2학기 프로젝트 조 편성 시 반영됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다음의 패키지들을 import 합니다.     \n",
    "    * pandas\n",
    "    * numpy\n",
    "    * matplotlib.pyplot\n",
    "    * sklearn.datasets : load_iris\n",
    "    * sklearn.preprocessing : OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "    * sklearn.model_selection : train_test_split\n",
    "    * keras.models : Sequential\n",
    "    * keras.layers : Dense\n",
    "    * keras.utils : to_categorical\n",
    "    * keras.optimizers : Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Iris Data를 불러옵니다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iris = ___________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* iris 데이터셋은 target과 data로 구성되어 있습니다. \n",
    "    * x와 y 각각에 data 값과 target 값을 저장해 봅시다. \n",
    "    * y의 경우 reshape()을 통해서 하나의 행에 하나의 target value가 들어가 있는 array 구조로 조정해 줍니다. \n",
    "    * ex) 1, 1, 2를 아래와 같이 조정하면 됩니다.  \n",
    "           [1],\n",
    "           [1],\n",
    "           [2], ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ____.____\n",
    "y_raw = ____.______.reshape(_,_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* y가 제대로 조정되었는지 확인해 봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_raw[__:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* y(target) 값을 n차원 행렬(array)로 바꾸어 줍니다. \n",
    "    * [0]을 [1, 0, 0]으로, [1]을 [0, 1, 0]으로, [2]를 [0, 0, 1]와 같은 구조로 변환시키는 것을 의미합니다.\n",
    "    * OneHotEncoder를 사용해서 진행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode the class labels\n",
    "_______ = OneHotEncoder(sparse=_____)\n",
    "y = _______.___________(y_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 제대로 y가 Encoding 되었는지 확인해 봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(______)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다음으로, train, test set을 분리합니다.\n",
    "    * test set의 size는 전체 데이터의 30%로 지정합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train, test split\n",
    "x_train, x_test, y_train, y_test = ______________(_, _, _________=___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[:_, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* x의 값들을 살펴보면, 변수별로 scale이 다르기 때문에 추가적인 scaling 과정이 필요합니다. \n",
    "    * MinMaxScaler 혹은 StandardScaler를 사용해서 scaling을 진행합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling \n",
    "#standardization\n",
    "scaler = ____________()\n",
    "#MinMaxScaling\n",
    "scaler = ____________()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scaler.___________(______)\n",
    "x_test = scaler.___________(______)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* scaling이 잘 진행되었는지 확인해 봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:_, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 우선, 가장 기본적인 Perceptron model을 구성해 봅시다.\n",
    "* Single Layer Perceptron은 입력층과 출력층만으로 구성되어 있습니다. \n",
    "    * Dense를 통해서 적절한 output dimension과 활성함수, input dimension을 결정하여 입력해 줍니다. \n",
    "    * 연쇄방법을 사용하여 작업을 진행합니다. (Sequential() and Dense()를 사용)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model\n",
    "model = Sequential()\n",
    "model.___(Dense(_, _______=__, _________=_______))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* optimizer : rmsprop \n",
    "* loss : categorical_crossentropy\n",
    "* metrics : accuracy                    \n",
    "다음과 같이 선택해서 모델의 학습과정을 설정합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습과정 설정하기 : \n",
    "model.______(_______ = ______, _______ = ______, _______ = ______)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* epochs : 100\n",
    "* batch_size : 64       \n",
    "와 같이 설정하여 모델을 학습시킵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습시키기\n",
    "____= model.fit(______, ______, _____=___, ________=__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train 과정의 loss와 accuracy 변화 추이를 확인해 봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.set_ylim([___, ___])   # range of loss \n",
    "acc_ax.set_ylim([___, ___])    # range of accuracy \n",
    "\n",
    "loss_ax.plot(____.history[_____], color_you_want , label = 'train loss')  #loss history\n",
    "acc_ax.plot(____.history[_____], color_you_want, label='train acc')  #accuracy history\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "loss_ax.legend(loc='lower left')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 마지막으로, 현재 모델에 test data를 적용시킨 결과를 살펴봅시다. \n",
    "* batch_size = 32로 진행합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model evaluation\n",
    "results = model.evaluate(_____, ______, _______=__)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final test set loss: {:4f}'.format(results[0]))\n",
    "print('Final test set accuracy: {:4f}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 번째로는, 여러개의 layer를 가지고 있는 구조를 구성해 보도록 합니다.         \n",
    "구조는 앞의 Single Layer Perceptron과 동일하고, layer를 추가해 주기만 하면 됩니다. \n",
    "* 처음 layer를 구성 할 때만 input dim을 설정해 주면 됩니다. (이후 layer들은 이전 모델에서 자동으로 설정됩니다.) \n",
    "* Hidden Layer의 activation function은 relu를 사용해 주세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model\n",
    "model = Sequential()\n",
    "model.___(Dense(__, ________=_ , ________=_____))\n",
    "model.___(Dense(__, ________=_____))\n",
    "model.___(Dense(__, ________=_____))\n",
    "model.___(Dense(_, ________=______))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* optimizer : Adam, learning rate = 0.4 (lr=0.04) \n",
    "* loss : categorical_crossentropy\n",
    "* metrics : accuracy          \n",
    "          \n",
    "다음과 같이 선택해서 모델의 학습과정을 설정합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "model.______(_______ = ______, _______ = ______, _______ = ______)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 아래를 통해서 현재 구성된 network의 구조를 살펴볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Neural Network Model Summary: ')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* epochs : 100     \n",
    "와 같이 설정하여 모델을 학습시킵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "____= model.fit(______, ______, verbose = 2, ______=___, ________=__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* single layer perceptron과 마찬가지로, train 과정에서 loss와 accuracy가 변화하는 것을 확인해 볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.set_ylim([___, ___])   # range of loss \n",
    "acc_ax.set_ylim([___, ___])    # range of accuracy \n",
    "\n",
    "loss_ax.plot(____.history[_____], color_you_want , label = 'train loss')  #loss history\n",
    "acc_ax.plot(____.history[_____], color_you_want, label='train acc')  #accuracy history\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "loss_ax.legend(loc='lower left')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 마지막으로, test data에 대해서 위의 model을 적용시켜 test accuracy를 계산합니다.\n",
    "* batch size는 32로 고정합니다. (따로 정하지 않아도 괜찮습니다.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test to unseen data\n",
    "results = model.evaluate(_____, ______, ________=___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final test set loss: {:4f}'.format(results[_]))\n",
    "print('Final test set accuracy: {:4f}'.format(results[_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
